# ChatBot - 本地大模型对话工具
## 一、工具简介
ChatBot 是基于 WPF MVVM设计模式和LLamaSharp开发的本地大模型对话应用，具备以下核心能力：  
- **模型支持**：支持`gguf` 格式大语言模型。  
- **交互体验**：采用气泡式对话框。  
- **性能加速**：集成 Vulkan GPU 加速。  
- **文档拓展**：支持添加文档附件。    

## 二、功能模块说明
### （一）模型加载与管理  
- **模型路径配置**：在“模型”界面，通过选择本地路径（如示例中 `D:\LlmModel` ），加载存储的 `gguf` 格式模型（如 `Qwen3-0.6B-Q8_0`、`Qwen3-1.7B-Q8_0` ），单机列表中的模型实现多模型便捷切换。  
- **模型参数适配**：使用LLamaSharp，结合 Vulkan GPU 加速可在设置中配置具体参数，优化模型推理性能。 

### （二）个性化设置  
- **主题切换**：“设置”界面提供“浅色/深色”主题选项，适配不同视觉偏好，优化界面显示效果。  
- **模型参数微调**：支持调整 `Total Gpu Layers`（GPU 分层数）、`Context Size`（上下文长度）、`Max Tokens`（最大 tokens 数 ）等，适配不同模型性能需求；可自定义 `初始化Prompt` 与 `回答结束语`，塑造专属交互逻辑。  

## 三、环境依赖与部署
### （一）环境要求  
- **系统**：Windows  
- **依赖库**：支持Vulkan GPU 加速的图形驱动。  

### （二）部署流程  
1. **代码获取**：克隆或下载本项目代码至本地开发环境。  
2. **依赖安装**：通过 .NET CLI 或 Visual Studio  NuGet 包管理器，还原项目依赖（如 WPF 基础库、GPU 加速相关组件 ）。  
3. **模型准备**：将 `gguf` 格式模型文件存放至本地路径（如 `D:\LlmModel` ），确保路径可访问。  
4. **运行调试**：启动 WPF 项目，在“模型”界面加载模型，进入“对话”界面即可开始交互，可在“设置”界面个性化配置。  

## 四、使用示例
1. **模型加载**：打开工具，切换至“模型”页，确认模型路径正确，选中目标 `gguf` 模型（如 `Qwen3-1.7B-Q8_0` ）完成加载。  
1. **初始化prompt**：填入恰当的初始化prompt，每次修改初始化prompt需要重载模型。
2. **发起对话**：进入“对话”页，输入问题（如“分析一下此文档的内容” ），点击“发送消息”，模型基于 `初始化Prompt` 规则（如判断文档类型、提取摘要等 ）回复，气泡式展示交互内容。  
3. **文档交互**：点击“附件 - 打开”上传文档，围绕文档内容提问，模型结合文档与知识推理回复。  
4. **流程控制**：对话中若需中断，点击终止按钮，停止当前推理；在“设置”页可切换主题、调整模型参数（如增大 `Context Size` 适配长文本 ），自定义交互体验。  

## 五、注意事项
- **模型兼容性**：严格确保模型为 `gguf` 格式，不同模型对参数（如 `Total Gpu Layers` ）适配性有差异，需根据模型说明、硬件性能调试，避免运行报错。  
- **GPU 加速依赖**：Vulkan GPU 加速需硬件与驱动支持，若加速异常，可检查驱动版本、切换 CPU 推理（Total Gpu Layers = 0 ）。  
- **文档大小限制**：过大文档可能导致加载缓慢、内存占用过高，建议预处理文档，控制单次交互内容规模，保障工具稳定运行。  

## 六、示例图片

![1](doc\img\164608.png)

![2](doc\img\164613.png)

![3](doc\img\164625.png)